{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZJU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mhmmdshirazi/laser_measurement/blob/master/ZJU.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "kZUEQVo_PjLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "b4a8e37c-735c-45a0-9749-8c8cdfee0712"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!wget https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!dpkg -i google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!apt-get install -f\n",
        "!apt-get -y install -qq fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "import cv2 as cv\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "!pip install -q torch\n",
        "!pip install -q torchvision\n",
        "!pip install -q scipy\n",
        "!pip install -q numpy\n",
        "\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "!pip install --no-cache-dir -I pillow\n",
        "\n",
        "\n",
        "\n",
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "import torch\n",
        "\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "!pip install --no-cache-dir -I pillow\n",
        "\n",
        "\n",
        "import os\n",
        "print(os.listdir(os.getcwd()))\n",
        "os.chdir('drive/AI/B')\n",
        "print(os.listdir(os.getcwd()))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "labels_to_atrs_dict = {}\n",
        "train_pics_dict={}\n",
        "train_pics_to_attr_dict = {}\n",
        "test_pics_list = []\n",
        "\n",
        "from sklearn import tree\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
        "Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions): \n",
        "  for extension in extensions: register_extension(id, extension)\n",
        "Image.register_extensions = register_extensions\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_label(file_name):\n",
        "    with open(file_name) as labels:\n",
        "        content = labels.read().split('\\n')\n",
        "    label_list = [x.split('\\t')[0] for x in content][:-1]\n",
        "    return label_list\n",
        "\n",
        "def load_label_attr(file_name):\n",
        "    with open(file_name) as labels:\n",
        "        content = labels.read().split('\\n')\n",
        "    label_attr = [list(map(float,x.split('\\t')[1:])) for x in content][:-1]\n",
        "    atrs = np.array(label_attr[0])\n",
        "    label_attr = label_attr[1:]\n",
        "    for i in label_attr:\n",
        "        ii = np.array(i)\n",
        "        atrs = np.vstack((atrs,ii))\n",
        "    return atrs\n",
        "\n",
        "def create_label_to_atr_dict():\n",
        "    labels_list = load_label('attributes_per_class.txt')\n",
        "    atrs_list = load_label_attr('attributes_per_class.txt')\n",
        "    for label in labels_list:\n",
        "        labels_to_atrs_dict[label] = atrs_list[labels_list.index(label)]\n",
        "\n",
        "def label_to_atr(label):\n",
        "    return labels_to_atrs_dict[label]\n",
        "import math\n",
        "def newAttr_to_label(atr):  \n",
        "    maxProduct = 0;\n",
        "    bestKey = 'ZJL1'\n",
        "    for key,value in labels_to_atrs_dict.items():\n",
        "        p = 1\n",
        "        for i in range(len(value)):\n",
        "            p = p * (math.fabs(atr[i] - value [i]))\n",
        "        if p > maxProduct :\n",
        "            maxProduct = p\n",
        "            bestKey = key\n",
        "    return bestKey\n",
        "\n",
        "def atr_to_label(atr):\n",
        "    for key,value in labels_to_atrs_dict.items():\n",
        "        try:\n",
        "            if set(value) == set(atr):\n",
        "                return key\n",
        "        except:\n",
        "            print('key is:', key, 'value shape is:', value.shape, 'atr shape is:', atr.shape)\n",
        "    tree = dsc_tree_train(load_label_attr('attributes_per_class.txt'),load_label('attributes_per_class.txt'))\n",
        "    tst_atr = np.array([atr])\n",
        "    return dsc_tree_prediction(tree,tst_atr)\n",
        "\n",
        "def create_train_pics_dict():\n",
        "    file_name = \"train.txt\"\n",
        "    with open(file_name) as pics_labels:\n",
        "        content = pics_labels.read().split('\\n')\n",
        "    pics_list = [x.split('\\t')[0] for x in content][:-1]\n",
        "    lables_list = [x.split('\\t')[1:] for x in content][:-1]\n",
        "    for pic in pics_list:\n",
        "        train_pics_dict[pic] = lables_list[pics_list.index(pic)][0]\n",
        "def create_test_pics_list():\n",
        "    file_name = \"image.txt\"\n",
        "    with open(file_name) as pics_labels:\n",
        "        a = pics_labels.read().split('\\n')[:-1]\n",
        "        test_pics_list.extend(a)\n",
        "def load_pic(pic_name,train_flag):\n",
        "    if train_flag:\n",
        "        pic = \"train/\"+pic_name\n",
        "    else:\n",
        "        pic = \"test/\"+pic_name\n",
        "    return Image.open(pic)\n",
        "\n",
        "def create_train_pic_atr_dict():\n",
        "    for pic,label in train_pics_dict.items():\n",
        "        train_pics_to_attr_dict[pic] = labels_to_atrs_dict[label]\n",
        "\n",
        "\n",
        "def dsc_tree_train(X,y):\n",
        "    attr_clf = tree.DecisionTreeClassifier()\n",
        "    attr_clf.fit(X,y)\n",
        "    return attr_clf\n",
        "\n",
        "def dsc_tree_prediction(clf,X):\n",
        "    return clf.predict(X)\n",
        "\n",
        "def save_obj(obj, name ):\n",
        "    with open('obj/'+ name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_obj(name):\n",
        "    with open('obj/' + name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def initialize():\n",
        "    global labels_to_atrs_dict, train_pics_to_attr_dict, train_pics_dict\n",
        "    try:\n",
        "        labels_to_atrs_dict = np.load('labels_to_atrs_dict.npy').items()\n",
        "    except:\n",
        "        create_label_to_atr_dict()\n",
        "        np.save('labels_to_atrs_dict.npy',labels_to_atrs_dict)\n",
        "    try:\n",
        "        train_pics_dict = np.load('train_pics_dict.npy').items()\n",
        "    except:\n",
        "        create_train_pics_dict()\n",
        "        np.save('train_pics_dict.npy',train_pics_dict)\n",
        "    try:\n",
        "        train_pics_to_attr_dict = np.load('train_pics_to_attr_dict.npy').items()\n",
        "    except:\n",
        "        create_train_pic_atr_dict()\n",
        "        np.save('train_pics_to_attr_dict.npy',train_pics_to_attr_dict)\n",
        "# def write_submition(img_name,label,write_in_new_file_flag):\n",
        "\n",
        "import random\n",
        "from os import walk\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "\n",
        "normalize = transforms.Normalize(\n",
        "   mean=[0.485, 0.456, 0.406],\n",
        "   std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "def LoadData(dir, trainPercentage, validSize):\n",
        "    train = []\n",
        "    trainLabels = []\n",
        "    validation = []\n",
        "    validLabels = []\n",
        "    i = 0\n",
        "    for (dirpath, dirnames, filenames) in walk(dir):\n",
        "        total = len(filenames)\n",
        "        random.shuffle(filenames)\n",
        "        for filename in filenames:\n",
        "            filepath = path.join(dirpath, filename)\n",
        "            imgCV = cv.imread(filepath)\n",
        "            #impp = np.reshape(img,(img.shape[2],img.shape[0],img.shape[1]))\n",
        "            img = Image.fromarray(imgCV)\n",
        "            \n",
        "            #print(impp.shape[0])\n",
        "            if imgCV.shape[2] != 3:\n",
        "                continue\n",
        "            \n",
        "            img_tensor = preprocess(img)\n",
        "            if(i%100 == 0):\n",
        "                print(\"loaded: \",i)\n",
        "            if(i <= int(trainPercentage * total)):\n",
        "                train.append(img_tensor)\n",
        "                trainLabels.append(filename)\n",
        "            elif len(validation) <  validSize:\n",
        "                validation.append(img_tensor)\n",
        "                validLabels.append(filename)\n",
        "            else:\n",
        "                break\n",
        "            i = i + 1\n",
        "    return train, trainLabels, validation, validLabels\n",
        "\n",
        "  \n",
        "trainImgs = []\n",
        "trainNames = []\n",
        "validImgs =[]\n",
        "validNames =[]\n",
        "(trainImgs,trainNames,validImgs,validNames) = LoadData('train',0.7,10000)\n",
        "\n",
        "initialize()\n",
        "\n",
        "####################### train\n",
        "attrList = []\n",
        "for trainName in trainNames:\n",
        "   attr = train_pics_to_attr_dict[trainName]\n",
        "   attrList.append(attr)\n",
        "\n",
        "target = torch.FloatTensor(attrList)\n",
        "print(\"kheili alaki\")\n",
        "def load_train_images(image_size=64, batch_size=64, root=\"./img/\"):\n",
        "\n",
        "    train_set = trainImgs\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=False, num_workers=1)\n",
        "    #train_loader.dataset.target = torch.FloatTensor([0,1])\n",
        "    return train_loader\n",
        "\n",
        "####################### validation\n",
        "attrListValid = []\n",
        "for validName in validNames:\n",
        "   attr = train_pics_to_attr_dict[validName]\n",
        "   attrListValid.append(attr)\n",
        "targetValid = torch.FloatTensor(attrListValid)\n",
        "print(\"kheili alaki\")\n",
        "def load_train_images_validation(image_size=64, batch_size=64, root=\"./img/\"):\n",
        "    train_set = validImgs\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=False, num_workers=1)\n",
        "    #train_loader.dataset.target = torch.FloatTensor([0,1])\n",
        "    return train_loader\n",
        "  \n",
        "  \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "#print(attr)\n",
        "torch.set_num_threads(16)\n",
        "train_loader = load_train_images()\n",
        "train_loader_valid = load_train_images_validation()\n",
        "####### CNN\n",
        "\n",
        "targetLearnSize = 30\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=50):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(2, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "#models = [ResNet(Bottleneck, [3, 8, 36, 3]) for _ in range(1)]\n",
        "#\n",
        "model = ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "model.cuda()\n",
        "\n",
        "#optimizer = torch.optim.Adam(model.parameters(),lr=0.01, betas=(0.9, 0.999))\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "def train(epoch):\n",
        "    print(\"train started\")\n",
        "    global train_loader\n",
        "    model.train()\n",
        "    # try:\n",
        "    for batch_idx,data in enumerate(train_loader):\n",
        "        #print(\"in train loop   \",batch_idx)\n",
        "        #data, target = Variable(data), Variable(target)\n",
        "        data = Variable(data).cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        #print(output)\n",
        "        criterion = nn.MSELoss()\n",
        "        try:\n",
        "            loss = criterion(output, Variable(target[batch_idx*64:(batch_idx+1)*64]).cuda())\n",
        "        except:\n",
        "            loss = criterion(output, Variable(target[batch_idx * 64: ]).cuda())\n",
        "        loss.backward()\n",
        "        #print(model.conv1.bias.grad)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if(batch_idx% 10 == 0) :\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
        "    # except:\n",
        "    #     for img in train_loader.dataset:\n",
        "    #         if img.shape != torch.Size([3,64,64]):\n",
        "    #             ews = type(train_loader.dataset)\n",
        "    #             idvv = train_loader.dataset.index(img)\n",
        "    #             print(trainNames[train_loader.dataset.index(img)])\n",
        "correctCounter = 0\n",
        "\n",
        "\n",
        "def test():\n",
        "    global correctCounter\n",
        "    correctCounter = 0\n",
        "    for batch_idx,data in enumerate(train_loader_valid):\n",
        "        data = Variable(data).cuda()\n",
        "#        s = data.detach().numpy().shape[0]\n",
        " #       testOP = np.empty([s, 30])\n",
        "#         for i in range(len(models)):\n",
        "#             output = models[i](data)\n",
        "#             output = output.detach().numpy()\n",
        "#             testOP[:, i] = output.flatten()\n",
        "        output = model(data).cpu().detach().numpy()\n",
        "        \n",
        "        print(batch_idx)\n",
        "        counter = 0\n",
        "        for op in output:\n",
        "            # m = atr_to_label(op)\n",
        "            # print(m ,'::::' ,validNames[counter],\"::::\",train_pics_dict[validNames[counter]])\n",
        "#             print(newAttr_to_label(op))\n",
        "#             print(train_pics_dict[validNames[counter +  batch_idx*64]])\n",
        "#             print('test',op)\n",
        "#             print('real',train_pics_to_attr_dict[validNames[counter +  batch_idx*64]])\n",
        "    \n",
        "            if newAttr_to_label(op) == train_pics_dict[validNames[counter +  batch_idx*64]]:\n",
        "                correctCounter = correctCounter + 1\n",
        "                print(newAttr_to_label(op))\n",
        "                print(train_pics_dict[validNames[counter +  batch_idx*64]])\n",
        "            \n",
        "            counter = counter + 1\n",
        "            \n",
        "try:            \n",
        "    model = torch.load(\"Save/model.pt\")\n",
        "except:\n",
        "    print('new model')\n",
        "print(train_loader)\n",
        "for epoch in range(1, 10000):\n",
        "    train(epoch)\n",
        "    torch.save(model, \"Save/model\"+ \".pt\")\n",
        "    if epoch%100 == 0:\n",
        "        test()\n",
        "        print(\"this is correct num:\",correctCounter,\"Pers:\",correctCounter/(len(validNames)))\n",
        "test()\n",
        "print(\"this is correct num:\",correctCounter,\"Pers:\",correctCounter/(len(validNames)))\n",
        "\n",
        "print(\"alaki\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log.59’.\n",
            "(Reading database ... 19845 files and directories currently installed.)\n",
            "Preparing to unpack google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.0-0ubuntu1) over (0.7.0-0ubuntu1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.0-0ubuntu1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
            "··········\n",
            "Collecting pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/24/f53ff6b61b3d728b90934bddb4f03f8ab584a7f49299bf3bde56e2952612/Pillow-5.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 2.6MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "Successfully installed pillow-5.2.0\n",
            "Collecting pillow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/24/f53ff6b61b3d728b90934bddb4f03f8ab584a7f49299bf3bde56e2952612/Pillow-5.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 57.4MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "Successfully installed pillow-5.2.0\n",
            "['google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.29', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.6', 'wget-log.52', 'wget-log.58', 'wget-log.28', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.49', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.13', 'wget-log.41', 'wget-log.42', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.45', 'wget-log.10', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.17', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.47', 'wget-log.29', 'wget-log.12', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.27', 'wget-log.18', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.21', 'wget-log.40', 'wget-log.33', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.9', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.41', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.58', 'wget-log.23', 'wget-log.36', 'wget-log.4', 'wget-log.55', 'wget-log.20', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.30', 'test', 'wget-log.13', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.43', 'class_wordembeddings.txt', 'Save', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.37', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.50', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.20', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.55', 'wget-log.1', 'labels_to_atrs_dict.npy', 'wget-log.31', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.12', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.42', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.59', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.11', 'wget-log.27', 'wget-log.39', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.35', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.33', 'wget-log.53', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.3', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.5', 'wget-log', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.52', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.34', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.10', 'wget-log.7', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.48', 'wget-log.49', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.2', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.26', 'wget-log.2', 'wget-log.14', 'wget-log.44', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.7', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.39', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.46', 'drive', 'wget-log.6', 'wget-log.32', 'wget-log.5', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.14', 'wget-log.25', 'wget-log.11', 'wget-log.8', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.19', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.8', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.54', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.15', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.44', 'train.txt', 'wget-log.54', 'wget-log.51', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.22', 'wget-log.9', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.40', 'attributes_per_class.txt', 'attribute_list.txt', 'wget-log.35', 'wget-log.50', 'wget-log.47', 'wget-log.30', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.28', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.31', 'wget-log.17', 'wget-log.34', 'wget-log.26', 'train_pics_to_attr_dict.npy', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.18', 'wget-log.19', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.57', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.23', 'wget-log.57', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.4', 'wget-log.38', 'wget-log.56', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.36', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.56', 'wget-log.59', 'wget-log.46', 'image.txt', 'wget-log.24', 'wget-log.43', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.1', 'train_pics_dict.npy', 'wget-log.48', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.32', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.24', 'wget-log.16', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.51', 'wget-log.45', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.16', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.38', 'label_list.txt', 'train', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb', 'wget-log.21', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.53', 'wget-log.3', 'wget-log.22', 'wget-log.15', 'wget-log.37', 'google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb.25']\n",
            "['train', 'test', 'attribute_list.txt', 'class_wordembeddings.txt', 'image.txt', 'attributes_per_class.txt', 'label_list.txt', 'train.txt', 'Save']\n",
            "loaded:  0\n",
            "loaded:  100\n",
            "loaded:  200\n",
            "loaded:  300\n",
            "loaded:  400\n",
            "loaded:  500\n",
            "loaded:  600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tyKkGpcYWoxJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    }
  ]
}